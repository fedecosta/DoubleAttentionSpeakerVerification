{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/')\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from train_3 import Trainer\n",
    "from settings import TRAIN_DEFAULT_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:31:35 - train_3 - INFO - Setting random seed...\n",
      "17:31:35 - train_3 - INFO - Random seed setted.\n",
      "17:31:35 - train_3 - INFO - Setting device...\n",
      "17:31:35 - train_3 - INFO - Running on cuda device.\n",
      "17:31:35 - train_3 - INFO - Device setted.\n",
      "17:31:35 - train_3 - INFO - Loading data and labels from /home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/labels/train/train_labels.ndx\n",
      "/home/usuaris/veu/federico.costa/.conda/envs/DASV/lib/python3.10/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "17:31:35 - train_3 - INFO - Data and labels loaded.\n",
      "17:31:35 - train_3 - INFO - Loading the network...\n",
      "17:31:37 - train_3 - INFO - Network loaded.\n",
      "17:31:37 - train_3 - INFO - Loading the loss function...\n",
      "17:31:37 - train_3 - INFO - Loss function loaded.\n",
      "17:31:37 - train_3 - INFO - Loading the optimizer...\n",
      "17:31:37 - train_3 - INFO - Optimizer adam loaded.\n",
      "17:31:37 - train_3 - INFO - Initializing training variables...\n",
      "17:31:37 - train_3 - INFO - Training variables initialized.\n"
     ]
    }
   ],
   "source": [
    "default_params_dict = TRAIN_DEFAULT_SETTINGS\n",
    "\n",
    "default_params_dict['train_labels_path'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/labels/train/train_labels.ndx'\n",
    "default_params_dict['valid_clients'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/labels/valid/valid_clients_labels.ndx'\n",
    "default_params_dict['valid_impostors'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/labels/valid/valid_impostors_labels.ndx'\n",
    "default_params_dict['max_epochs'] = 1000\n",
    "default_params_dict['eval_and_save_best_model_every'] = 10\n",
    "default_params_dict['early_stopping'] = 25\n",
    "default_params_dict['update_optimizer_every'] = 20\n",
    "\n",
    "default_params = argparse.Namespace(**default_params_dict)\n",
    "\n",
    "trainer = Trainer(default_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:31:37 - train_3 - INFO - Starting training for 1000 epochs.\n",
      "17:31:37 - train_3 - INFO - Epoch 0...\n",
      "17:31:37 - train_3 - INFO - Batch 0 of 17...\n",
      "17:31:39 - train_3 - INFO - Actual loss: 14.23\n",
      "17:31:41 - train_3 - INFO - Batch 1 of 17...\n",
      "17:31:41 - train_3 - INFO - Actual loss: 13.87\n",
      "17:31:41 - train_3 - INFO - Batch 2 of 17...\n",
      "17:31:43 - train_3 - INFO - Actual loss: 14.19\n",
      "17:31:43 - train_3 - INFO - Batch 3 of 17...\n",
      "17:31:45 - train_3 - INFO - Actual loss: 13.69\n",
      "17:31:45 - train_3 - INFO - Batch 4 of 17...\n",
      "17:31:47 - train_3 - INFO - Actual loss: 13.24\n",
      "17:31:47 - train_3 - INFO - Batch 5 of 17...\n",
      "17:31:48 - train_3 - INFO - Actual loss: 13.73\n",
      "17:31:48 - train_3 - INFO - Batch 6 of 17...\n",
      "17:31:50 - train_3 - INFO - Actual loss: 13.25\n",
      "17:31:50 - train_3 - INFO - Batch 7 of 17...\n",
      "17:31:52 - train_3 - INFO - Actual loss: 13.76\n",
      "17:31:52 - train_3 - INFO - Batch 8 of 17...\n",
      "17:31:53 - train_3 - INFO - Actual loss: 13.74\n",
      "17:31:53 - train_3 - INFO - Batch 9 of 17...\n",
      "17:31:55 - train_3 - INFO - Actual loss: 13.57\n",
      "17:31:55 - train_3 - INFO - Batch 10 of 17...\n",
      "17:31:57 - train_3 - INFO - Actual loss: 13.78\n",
      "17:31:57 - train_3 - INFO - Evaluating training...\n",
      "17:31:58 - train_3 - INFO - Accuracy on training set: 0.33\n",
      "17:31:58 - train_3 - INFO - Evaluating validation...\n",
      "17:32:05 - train_3 - INFO - EER on validation set: 43.00\n",
      "17:32:05 - train_3 - INFO - We found a better model!\n",
      "17:32:05 - train_3 - INFO - Best model train loss: 13.78\n",
      "17:32:05 - train_3 - INFO - Best model train evaluation metric: 0.33\n",
      "17:32:05 - train_3 - INFO - Best model validation evaluation metric: 43.00\n",
      "17:32:08 - train_3 - INFO - Consecutive validations without improvement: 0\n",
      "17:32:08 - train_3 - INFO - Batch 11 of 17...\n",
      "17:32:09 - train_3 - INFO - Actual loss: 13.61\n",
      "17:32:09 - train_3 - INFO - Batch 12 of 17...\n",
      "17:32:10 - train_3 - INFO - Actual loss: 13.52\n",
      "17:32:11 - train_3 - INFO - Batch 13 of 17...\n",
      "17:32:12 - train_3 - INFO - Actual loss: 13.52\n",
      "17:32:12 - train_3 - INFO - Batch 14 of 17...\n",
      "17:32:14 - train_3 - INFO - Actual loss: 13.38\n",
      "17:32:14 - train_3 - INFO - Batch 15 of 17...\n",
      "17:32:16 - train_3 - INFO - Actual loss: 13.15\n",
      "17:32:16 - train_3 - INFO - Batch 16 of 17...\n",
      "17:32:17 - train_3 - INFO - Actual loss: 11.84\n",
      "17:32:17 - train_3 - INFO - --------------------------------------------------\n",
      "17:32:17 - train_3 - INFO - Epoch 0 finished with:\n",
      "17:32:17 - train_3 - INFO - Loss 11.84\n",
      "17:32:17 - train_3 - INFO - Best model training evaluation metric: 0.33\n",
      "17:32:17 - train_3 - INFO - Best model validation evaluation metric: 43.00\n",
      "17:32:17 - train_3 - INFO - --------------------------------------------------\n",
      "17:32:17 - train_3 - INFO - Epoch 1...\n",
      "17:32:17 - train_3 - INFO - Batch 0 of 17...\n",
      "17:32:18 - train_3 - INFO - Actual loss: 12.68\n",
      "17:32:18 - train_3 - INFO - Batch 1 of 17...\n",
      "17:32:20 - train_3 - INFO - Actual loss: 13.53\n",
      "17:32:20 - train_3 - INFO - Batch 2 of 17...\n",
      "17:32:21 - train_3 - INFO - Actual loss: 13.38\n",
      "17:32:21 - train_3 - INFO - Batch 3 of 17...\n",
      "17:32:23 - train_3 - INFO - Actual loss: 13.28\n",
      "17:32:23 - train_3 - INFO - Evaluating training...\n",
      "17:32:24 - train_3 - INFO - Accuracy on training set: 0.41\n",
      "17:32:24 - train_3 - INFO - Evaluating validation...\n",
      "17:32:32 - train_3 - INFO - EER on validation set: 43.00\n",
      "17:32:32 - train_3 - INFO - Consecutive validations without improvement: 1\n",
      "17:32:32 - train_3 - INFO - Batch 4 of 17...\n",
      "17:32:32 - train_3 - INFO - Actual loss: 12.06\n",
      "17:32:32 - train_3 - INFO - Batch 5 of 17...\n",
      "17:32:34 - train_3 - INFO - Actual loss: 13.48\n",
      "17:32:34 - train_3 - INFO - Batch 6 of 17...\n",
      "17:32:36 - train_3 - INFO - Actual loss: 13.06\n",
      "17:32:36 - train_3 - INFO - Batch 7 of 17...\n",
      "17:32:38 - train_3 - INFO - Actual loss: 13.16\n",
      "17:32:38 - train_3 - INFO - Batch 8 of 17...\n",
      "17:32:39 - train_3 - INFO - Actual loss: 13.00\n",
      "17:32:39 - train_3 - INFO - Batch 9 of 17...\n",
      "17:32:41 - train_3 - INFO - Actual loss: 12.74\n",
      "17:32:41 - train_3 - INFO - Batch 10 of 17...\n",
      "17:32:43 - train_3 - INFO - Actual loss: 12.65\n",
      "17:32:43 - train_3 - INFO - Batch 11 of 17...\n",
      "17:32:44 - train_3 - INFO - Actual loss: 12.83\n",
      "17:32:44 - train_3 - INFO - Batch 12 of 17...\n",
      "17:32:46 - train_3 - INFO - Actual loss: 12.81\n",
      "17:32:46 - train_3 - INFO - Batch 13 of 17...\n",
      "17:32:48 - train_3 - INFO - Actual loss: 12.84\n",
      "17:32:48 - train_3 - INFO - Evaluating training...\n",
      "17:32:49 - train_3 - INFO - Accuracy on training set: 0.42\n",
      "17:32:49 - train_3 - INFO - Evaluating validation...\n",
      "17:32:57 - train_3 - INFO - EER on validation set: 45.00\n",
      "17:32:57 - train_3 - INFO - Consecutive validations without improvement: 2\n",
      "17:32:57 - train_3 - INFO - Batch 14 of 17...\n",
      "17:32:57 - train_3 - INFO - Actual loss: 12.54\n",
      "17:32:57 - train_3 - INFO - Batch 15 of 17...\n",
      "17:32:59 - train_3 - INFO - Actual loss: 13.07\n",
      "17:32:59 - train_3 - INFO - Batch 16 of 17...\n",
      "17:33:00 - train_3 - INFO - Actual loss: 12.08\n",
      "17:33:00 - train_3 - INFO - --------------------------------------------------\n",
      "17:33:00 - train_3 - INFO - Epoch 1 finished with:\n",
      "17:33:00 - train_3 - INFO - Loss 12.08\n",
      "17:33:00 - train_3 - INFO - Best model training evaluation metric: 0.33\n",
      "17:33:00 - train_3 - INFO - Best model validation evaluation metric: 43.00\n",
      "17:33:00 - train_3 - INFO - --------------------------------------------------\n",
      "17:33:00 - train_3 - INFO - Epoch 2...\n",
      "17:33:01 - train_3 - INFO - Batch 0 of 17...\n",
      "17:33:01 - train_3 - INFO - Actual loss: 12.66\n",
      "17:33:01 - train_3 - INFO - Batch 1 of 17...\n",
      "17:33:03 - train_3 - INFO - Actual loss: 12.39\n",
      "17:33:03 - train_3 - INFO - Batch 2 of 17...\n",
      "17:33:05 - train_3 - INFO - Actual loss: 12.93\n",
      "17:33:05 - train_3 - INFO - Batch 3 of 17...\n",
      "17:33:06 - train_3 - INFO - Actual loss: 12.38\n",
      "17:33:06 - train_3 - INFO - Batch 4 of 17...\n",
      "17:33:08 - train_3 - INFO - Actual loss: 12.92\n",
      "17:33:08 - train_3 - INFO - Batch 5 of 17...\n",
      "17:33:10 - train_3 - INFO - Actual loss: 13.74\n",
      "17:33:10 - train_3 - INFO - Batch 6 of 17...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git_repositories/DoubleAttentionSpeakerVerification/scripts/train_3.py:419\u001b[0m, in \u001b[0;36mTrainer.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_input_params()\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarting_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git_repositories/DoubleAttentionSpeakerVerification/scripts/train_3.py:408\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, starting_epoch, max_epochs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_info \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting_epoch, max_epochs):  \n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/git_repositories/DoubleAttentionSpeakerVerification/scripts/train_3.py:327\u001b[0m, in \u001b[0;36mTrainer.train_single_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    324\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Assign input and label to device\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28minput\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, label\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Slice at random using the frames axis, if desired.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_slice(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mrandom_slicing \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.debug_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [item[\"step\"] for item in trainer.debug_info]\n",
    "train_loss = [item[\"train_loss\"] for item in trainer.debug_info]\n",
    "train_eval_metric = [item[\"train_eval_metric\"] for item in trainer.debug_info]\n",
    "valid_eval_metric = [item[\"valid_eval_metric\"] for item in trainer.debug_info]\n",
    "best_train_loss = [item[\"best_train_loss\"] for item in trainer.debug_info]\n",
    "best_model_train_eval_metric = [item[\"best_model_train_eval_metric\"] for item in trainer.debug_info]\n",
    "best_model_valid_eval_metric = [item[\"best_model_valid_eval_metric\"] for item in trainer.debug_info]\n",
    "validations_without_improvement = [item[\"validations_without_improvement\"] for item in trainer.debug_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10), dpi = 300)\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(steps, train_loss, linewidth = 1, label = \"train_loss\")\n",
    "# plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(steps, valid_eval_metric, label = \"validation EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "plt.ylim(0, 50)\n",
    "plt.ylabel(\"EER\")\n",
    "plt.title(\"Validation evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(steps, validations_without_improvement, label = \"validations_without_improvement\")\n",
    "plt.axhline(trainer.params.early_stopping, linestyle = \"--\", color = \"grey\")\n",
    "plt.ylim(0, trainer.params.early_stopping + 1)\n",
    "plt.ylabel(\"validations_without_improvement\")\n",
    "plt.title(\"Early stoping\")\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.suptitle(\"Training Process\", fontweight = 'bold', fontsize = 16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['model_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_loss, label = \"train_loss\")\n",
    "plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, valid_eval_metric, label = \"valid EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 50)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number, (input, label) in enumerate(trainer.training_generator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASV",
   "language": "python",
   "name": "dasv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
