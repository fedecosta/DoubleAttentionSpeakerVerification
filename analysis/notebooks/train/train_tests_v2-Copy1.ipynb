{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfedericocosta1989\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/notebooks/train/wandb/run-20221102_163401-324ybgb9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/federicocosta1989/speaker_verification/runs/324ybgb9\" target=\"_blank\">gentle-sea-15</a></strong> to <a href=\"https://wandb.ai/federicocosta1989/speaker_verification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/')\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from train import Trainer\n",
    "from settings import TRAIN_DEFAULT_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-11-02 16:34:07 - train - INFO - Setting device...\n",
      "22-11-02 16:34:07 - train - INFO - Running on cuda device.\n",
      "22-11-02 16:34:07 - train - INFO - Device setted.\n",
      "22-11-02 16:34:07 - train - INFO - Setting random seed...\n",
      "22-11-02 16:34:07 - train - INFO - Random seed setted.\n",
      "22-11-02 16:34:07 - train - INFO - Setting params...\n",
      "22-11-02 16:34:07 - train - INFO - params setted.\n",
      "22-11-02 16:34:07 - train - INFO - Loading data and labels from /home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/train/tiny_check/train_labels.ndx\n",
      "22-11-02 16:34:07 - train - INFO - Defining the random crop size in frames from a sample...\n",
      "22-11-02 16:34:07 - train - INFO - (We are assuming that all files in the dataset have the same spectrogram settings).\n",
      "22-11-02 16:34:07 - train - INFO - Random crop size calculated: 344 frames (eq to 3.5 seconds).\n",
      "22-11-02 16:34:07 - train - INFO - Data and labels loaded.\n",
      "22-11-02 16:34:07 - train - INFO - Loading the network...\n",
      "22-11-02 16:34:13 - train - INFO - Network loaded.\n",
      "22-11-02 16:34:13 - train - INFO - Loading the loss function...\n",
      "22-11-02 16:34:13 - train - INFO - Loss function loaded.\n",
      "22-11-02 16:34:13 - train - INFO - Loading the optimizer...\n",
      "22-11-02 16:34:13 - train - INFO - Optimizer adam loaded.\n",
      "22-11-02 16:34:13 - train - INFO - Initializing training variables...\n",
      "22-11-02 16:34:13 - train - INFO - Training variables initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─VGGNL: 1-1                             --\n",
      "|    └─Sequential: 2-1                   --\n",
      "|    |    └─Sequential: 3-1              148,864\n",
      "|    |    └─Sequential: 3-2              885,248\n",
      "|    |    └─Sequential: 3-3              3,539,968\n",
      "|    |    └─Sequential: 3-4              14,157,824\n",
      "├─Attention: 1-2                         5,120\n",
      "├─Linear: 1-3                            2,048,400\n",
      "├─BatchNorm1d: 1-4                       800\n",
      "├─Linear: 1-5                            160,400\n",
      "├─BatchNorm1d: 1-6                       800\n",
      "├─Linear: 1-7                            160,400\n",
      "├─BatchNorm1d: 1-8                       800\n",
      "├─Softmax: 1-9                           --\n",
      "├─AMSoftmax: 1-10                        2,000\n",
      "=================================================================\n",
      "Total params: 21,110,624\n",
      "Trainable params: 21,110,624\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "default_params_dict = TRAIN_DEFAULT_SETTINGS\n",
    "\n",
    "default_params_dict['train_labels_path'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/train/tiny_check/train_labels.ndx'\n",
    "default_params_dict['valid_clients'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/valid/voxceleb_2/clients.ndx'\n",
    "default_params_dict['valid_impostors'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/valid/voxceleb_2/impostors.ndx'\n",
    "default_params_dict['eval_and_save_best_model_every'] = 10\n",
    "default_params_dict['early_stopping'] = 25\n",
    "default_params_dict['update_optimizer_every'] = 20\n",
    "default_params_dict['pooling_method'] = 'Attention'\n",
    "\n",
    "default_params = argparse.Namespace(**default_params_dict)\n",
    "\n",
    "trainer = Trainer(default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048400"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*5 * 400 + 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21110624"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21110624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([5120, 1])\n",
      "torch.Size([400, 5120])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 400])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 400])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 5])\n"
     ]
    }
   ],
   "source": [
    "for p in list(model.parameters()):\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeakerClassifier(\n",
       "  (front_end): VGGNL(\n",
       "    (conv_blocks): Sequential(\n",
       "      (convolutional_block_1): Sequential(\n",
       "        (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (convolutional_block_2): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (convolutional_block_3): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (convolutional_block_4): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (poolingLayer): Attention()\n",
       "  (fc1): Linear(in_features=5120, out_features=400, bias=True)\n",
       "  (b1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (b2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (b3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (am_softmax_layer): AMSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[3].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[4].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[5].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[6].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[7].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 256, 3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[8].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.debug_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [item[\"step\"] for item in trainer.debug_info]\n",
    "train_loss = [item[\"train_loss\"] for item in trainer.debug_info]\n",
    "train_eval_metric = [item[\"train_eval_metric\"] for item in trainer.debug_info]\n",
    "valid_eval_metric = [item[\"valid_eval_metric\"] for item in trainer.debug_info]\n",
    "best_train_loss = [item[\"best_train_loss\"] for item in trainer.debug_info]\n",
    "best_model_train_eval_metric = [item[\"best_model_train_eval_metric\"] for item in trainer.debug_info]\n",
    "best_model_valid_eval_metric = [item[\"best_model_valid_eval_metric\"] for item in trainer.debug_info]\n",
    "validations_without_improvement = [item[\"validations_without_improvement\"] for item in trainer.debug_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10), dpi = 300)\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(steps, train_loss, linewidth = 1, label = \"train_loss\")\n",
    "# plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(steps, valid_eval_metric, label = \"validation EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "plt.ylim(0, 50)\n",
    "plt.ylabel(\"EER\")\n",
    "plt.title(\"Validation evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(steps, validations_without_improvement, label = \"validations_without_improvement\")\n",
    "plt.axhline(trainer.params.early_stopping, linestyle = \"--\", color = \"grey\")\n",
    "plt.ylim(0, trainer.params.early_stopping + 1)\n",
    "plt.ylabel(\"validations_without_improvement\")\n",
    "plt.title(\"Early stoping\")\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.suptitle(\"Training Process\", fontweight = 'bold', fontsize = 16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['model_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_loss, label = \"train_loss\")\n",
    "plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, valid_eval_metric, label = \"valid EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 50)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number, (input, label) in enumerate(trainer.training_generator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainer.params.train_labels_path, 'r') as data_labels_file:\n",
    "    train_labels = data_labels_file.readlines()\n",
    "    \n",
    "train_label = train_labels[0]\n",
    "\n",
    "pickle_path = train_label.replace(\"\\n\", \"\").split(\" \")[0] + \".pickle\"\n",
    "\n",
    "with open(pickle_path, 'rb') as pickle_file:\n",
    "    features_dict = pickle.load(pickle_file)\n",
    "    \n",
    "features = features_dict[\"features\"]\n",
    "features_settings = features_dict[\"settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASV",
   "language": "python",
   "name": "dasv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
