{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/scripts/')\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from train import Trainer\n",
    "from settings import TRAIN_DEFAULT_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-10-26 11:46:59 - train - INFO - Setting device...\n",
      "22-10-26 11:47:00 - train - INFO - Running on cuda device.\n",
      "22-10-26 11:47:00 - train - INFO - 8 GPUs available.\n",
      "22-10-26 11:47:00 - train - INFO - Device setted.\n",
      "22-10-26 11:47:00 - train - INFO - Setting random seed...\n",
      "22-10-26 11:47:00 - train - INFO - Random seed setted.\n",
      "22-10-26 11:47:00 - train - INFO - Setting params...\n",
      "22-10-26 11:47:00 - train - INFO - params setted.\n",
      "22-10-26 11:47:00 - train - INFO - Loading data and labels from /home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/train/tiny_check/train_labels.ndx\n",
      "22-10-26 11:47:00 - train - INFO - Data and labels loaded.\n",
      "22-10-26 11:47:00 - train - INFO - Loading the network...\n",
      "22-10-26 11:47:04 - train - INFO - Let's use 8 GPUs!\n",
      "22-10-26 11:47:04 - train - INFO - Network loaded.\n",
      "22-10-26 11:47:04 - train - INFO - Loading the loss function...\n",
      "22-10-26 11:47:04 - train - INFO - Loss function loaded.\n",
      "22-10-26 11:47:04 - train - INFO - Loading the optimizer...\n",
      "22-10-26 11:47:04 - train - INFO - Optimizer adam loaded.\n",
      "22-10-26 11:47:04 - train - INFO - Initializing training variables...\n",
      "22-10-26 11:47:04 - train - INFO - Training variables initialized.\n"
     ]
    }
   ],
   "source": [
    "default_params_dict = TRAIN_DEFAULT_SETTINGS\n",
    "\n",
    "default_params_dict['train_labels_path'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/train/tiny_check/train_labels.ndx'\n",
    "default_params_dict['valid_clients'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/valid/voxceleb_2/clients.ndx'\n",
    "default_params_dict['valid_impostors'] = '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/labels/valid/voxceleb_2/impostors.ndx'\n",
    "default_params_dict['eval_and_save_best_model_every'] = 10\n",
    "default_params_dict['early_stopping'] = 25\n",
    "default_params_dict['update_optimizer_every'] = 20\n",
    "\n",
    "default_params = argparse.Namespace(**default_params_dict)\n",
    "\n",
    "trainer = Trainer(default_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.debug_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [item[\"step\"] for item in trainer.debug_info]\n",
    "train_loss = [item[\"train_loss\"] for item in trainer.debug_info]\n",
    "train_eval_metric = [item[\"train_eval_metric\"] for item in trainer.debug_info]\n",
    "valid_eval_metric = [item[\"valid_eval_metric\"] for item in trainer.debug_info]\n",
    "best_train_loss = [item[\"best_train_loss\"] for item in trainer.debug_info]\n",
    "best_model_train_eval_metric = [item[\"best_model_train_eval_metric\"] for item in trainer.debug_info]\n",
    "best_model_valid_eval_metric = [item[\"best_model_valid_eval_metric\"] for item in trainer.debug_info]\n",
    "validations_without_improvement = [item[\"validations_without_improvement\"] for item in trainer.debug_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10), dpi = 300)\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(steps, train_loss, linewidth = 1, label = \"train_loss\")\n",
    "# plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(steps, valid_eval_metric, label = \"validation EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "plt.ylim(0, 50)\n",
    "plt.ylabel(\"EER\")\n",
    "plt.title(\"Validation evaluation\")\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(steps, validations_without_improvement, label = \"validations_without_improvement\")\n",
    "plt.axhline(trainer.params.early_stopping, linestyle = \"--\", color = \"grey\")\n",
    "plt.ylim(0, trainer.params.early_stopping + 1)\n",
    "plt.ylabel(\"validations_without_improvement\")\n",
    "plt.title(\"Early stoping\")\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.suptitle(\"Training Process\", fontweight = 'bold', fontsize = 16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint['model_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_loss, label = \"train_loss\")\n",
    "plt.plot(steps, best_train_loss, \"--\", label = \"best_train_loss\")\n",
    "\n",
    "plt.ylim(0, max(train_loss))\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, train_eval_metric, label = \"train accuracy\")\n",
    "plt.plot(steps, best_model_train_eval_metric, \"--\", label = \"best_model_train_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6), dpi = 300)\n",
    "\n",
    "plt.plot(steps, valid_eval_metric, label = \"valid EER\")\n",
    "plt.plot(steps, best_model_valid_eval_metric, \"--\", label = \"best_model_valid_eval_metric\")\n",
    "\n",
    "plt.ylim(0, 50)\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.title(\"Evaluation metrics\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number, (input, label) in enumerate(trainer.training_generator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainer.params.train_labels_path, 'r') as data_labels_file:\n",
    "    train_labels = data_labels_file.readlines()\n",
    "    \n",
    "train_label = train_labels[0]\n",
    "\n",
    "pickle_path = train_label.replace(\"\\n\", \"\").split(\" \")[0] + \".pickle\"\n",
    "\n",
    "with open(pickle_path, 'rb') as pickle_file:\n",
    "    features_dict = pickle.load(pickle_file)\n",
    "    \n",
    "features = features_dict[\"features\"]\n",
    "features_settings = features_dict[\"settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(audio_paths_file_folder='./feature_extractor/', audio_paths_file_name='voxceleb_2_dev_feature_extractor_paths.lst', log_file_folder='./logs', log_file_name='feature_extractor_voxceleb_2_dev.log', sampling_rate=16000, n_fft_secs=0.023, window='hamming', win_length_secs=0.023, hop_length_secs=0.01, pre_emph_coef=0.97, n_mels=80, overwrite=True, verbose=False, audio_paths_file_path='./feature_extractor/voxceleb_2_dev_feature_extractor_paths.lst')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/usuaris/veussd/DATABASES/VoxCeleb/VoxCeleb2/dev/id06338/O_xVOYPnD9I/00017 0 -1\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASV",
   "language": "python",
   "name": "dasv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
